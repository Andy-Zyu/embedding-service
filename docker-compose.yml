version: '3.8'

services:
  # CPU版本服务
  embedding-service-cpu:
    build:
      context: .
      dockerfile: cpu/Dockerfile
    image: embedding-service:cpu
    container_name: embedding-service-cpu
    ports:
      - "8080:8080"
    environment:
      - MODEL_NAME=google/siglip2-so400m-patch16-naflex
      - PORT=8080
      - HOST=0.0.0.0
    volumes:
      # 可选：挂载HuggingFace缓存目录以加速模型加载
      - huggingface_cache:/app/.cache/huggingface
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # GPU版本服务
  embedding-service-gpu:
    build:
      context: .
      dockerfile: gpu/Dockerfile
    image: embedding-service:gpu
    container_name: embedding-service-gpu
    ports:
      - "8081:8080"
    environment:
      - MODEL_NAME=google/siglip2-so400m-patch16-naflex
      - PORT=8080
      - HOST=0.0.0.0
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      # 可选：挂载HuggingFace缓存目录以加速模型加载
      - huggingface_cache:/app/.cache/huggingface
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  huggingface_cache:
    driver: local

