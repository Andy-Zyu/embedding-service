version: '3.8'

services:
  # CPU版本服务 - 单实例（适合小规模使用）
  embedding-service-cpu:
    build:
      context: .
      dockerfile: cpu/Dockerfile
    image: embedding-service:cpu
    container_name: embedding-service-cpu
    ports:
      - "8080:8080"
    environment:
      - MODEL_NAME=google/siglip2-so400m-patch16-naflex
      - PORT=8080
      - HOST=0.0.0.0
      - WORKERS=4
      - WORKER_CLASS=sync
      - THREADS=2
      - TIMEOUT=120
    volumes:
      - huggingface_cache:/app/.cache/huggingface
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 8G
        reservations:
          cpus: '4'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # GPU版本服务 - 单实例（适合小规模使用）
  embedding-service-gpu:
    build:
      context: .
      dockerfile: gpu/Dockerfile
    image: embedding-service:gpu
    container_name: embedding-service-gpu
    ports:
      - "8081:8080"
    environment:
      - MODEL_NAME=google/siglip2-so400m-patch16-naflex
      - PORT=8080
      - HOST=0.0.0.0
      - WORKERS=2
      - WORKER_CLASS=sync
      - THREADS=4
      - TIMEOUT=120
      - CUDA_VISIBLE_DEVICES=0
    volumes:
      - huggingface_cache:/app/.cache/huggingface
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  huggingface_cache:
    driver: local
