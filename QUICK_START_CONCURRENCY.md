# Embedding Service å¹¶å‘èƒ½åŠ›å¿«é€Ÿå‚è€ƒ

## ğŸ“Š å¹¶å‘èƒ½åŠ›æ€»ç»“

### å½“å‰ç‰ˆæœ¬ï¼ˆFlaskå¼€å‘æœåŠ¡å™¨ï¼‰

| ç‰ˆæœ¬ | å¹¶å‘æ•° | RPS | é€‚ç”¨åœºæ™¯ |
|------|--------|-----|----------|
| **CPUç‰ˆæœ¬** | 30-50 | 15-25 | å¼€å‘/æµ‹è¯•ç¯å¢ƒ |
| **GPUç‰ˆæœ¬** | 50-100 | 100-200 | å¼€å‘/æµ‹è¯•ç¯å¢ƒ |

### ç”Ÿäº§ç‰ˆæœ¬ï¼ˆGunicornä¼˜åŒ–ï¼‰

| ç‰ˆæœ¬ | å¹¶å‘æ•° | RPS | é€‚ç”¨åœºæ™¯ |
|------|--------|-----|----------|
| **CPUç‰ˆæœ¬** | 100-200 | 50-100 | ç”Ÿäº§ç¯å¢ƒï¼ˆ4-8æ ¸CPUï¼‰ |
| **GPUç‰ˆæœ¬** | 200-400 | 200-400 | ç”Ÿäº§ç¯å¢ƒï¼ˆRTX 3090/A100ï¼‰ |

## ğŸš€ å¿«é€Ÿéƒ¨ç½²ç”Ÿäº§ç‰ˆæœ¬

### 1. æ„å»ºç”Ÿäº§é•œåƒ

```bash
cd /data/embedding-service

# CPUç‰ˆæœ¬
docker build -f cpu/Dockerfile.prod -t embedding-service:cpu-prod .

# GPUç‰ˆæœ¬
docker build -f gpu/Dockerfile.prod -t embedding-service:gpu-prod .
```

### 2. è¿è¡Œç”Ÿäº§ç‰ˆæœ¬

```bash
# CPUç‰ˆæœ¬ï¼ˆ4 workers, 2 threads eachï¼‰
docker run -d \
  --name embedding-cpu-prod \
  -p 8080:8080 \
  -e WORKERS=4 \
  -e THREADS=2 \
  embedding-service:cpu-prod

# GPUç‰ˆæœ¬ï¼ˆ2 workers, 4 threads eachï¼‰
docker run -d \
  --name embedding-gpu-prod \
  --gpus all \
  -p 8081:8080 \
  -e WORKERS=2 \
  -e THREADS=4 \
  embedding-service:gpu-prod
```

### 3. ä½¿ç”¨Docker Compose

```bash
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ“ˆ æ€§èƒ½æµ‹è¯•

### ä½¿ç”¨benchmark.pyå·¥å…·

```bash
# å®‰è£…ä¾èµ–
pip install aiohttp requests

# åŸºç¡€æµ‹è¯•
python benchmark.py --url http://localhost:8080 --concurrency 10 --requests 100

# ä¸­ç­‰å‹åŠ›æµ‹è¯•
python benchmark.py --url http://localhost:8080 --concurrency 50 --requests 500

# é«˜å‹åŠ›æµ‹è¯•
python benchmark.py --url http://localhost:8080 --concurrency 100 --requests 1000
```

## âš™ï¸ é…ç½®è°ƒä¼˜

### CPUç‰ˆæœ¬æ¨èé…ç½®

```bash
# 4æ ¸CPU
WORKERS=4 THREADS=2

# 8æ ¸CPU
WORKERS=8 THREADS=2

# 16æ ¸CPU
WORKERS=8 THREADS=4  # æˆ– WORKERS=16 THREADS=2
```

### GPUç‰ˆæœ¬æ¨èé…ç½®

```bash
# RTX 3090 (24GB)
WORKERS=2 THREADS=4

# A100 (40GB)
WORKERS=2 THREADS=8
```

## ğŸ”§ é«˜å¹¶å‘ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: å•å®ä¾‹ä¼˜åŒ–ï¼ˆæ¨èï¼‰

ä½¿ç”¨Gunicornç”Ÿäº§ç‰ˆæœ¬ï¼Œé…ç½®åˆé€‚çš„workerså’Œthreadsã€‚

### æ–¹æ¡ˆ2: å¤šå®ä¾‹éƒ¨ç½²

```bash
# å¯åŠ¨å¤šä¸ªå®ä¾‹
docker run -d -p 8080:8080 --name embedding-1 embedding-service:gpu-prod
docker run -d -p 8081:8080 --name embedding-2 embedding-service:gpu-prod
docker run -d -p 8082:8080 --name embedding-3 embedding-service:gpu-prod

# ä½¿ç”¨Nginxè´Ÿè½½å‡è¡¡
# nginxé…ç½®ç¤ºä¾‹è§ä¸‹æ–¹
```

### Nginxè´Ÿè½½å‡è¡¡é…ç½®ç¤ºä¾‹

```nginx
upstream embedding_backend {
    least_conn;
    server localhost:8080;
    server localhost:8081;
    server localhost:8082;
}

server {
    listen 80;
    server_name embedding.example.com;

    location / {
        proxy_pass http://embedding_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## ğŸ“ æ€§èƒ½ç›‘æ§

### ç›‘æ§æŒ‡æ ‡

- **å“åº”æ—¶é—´**: P50, P95, P99
- **ååé‡**: RPS (Requests Per Second)
- **é”™è¯¯ç‡**: å¤±è´¥è¯·æ±‚ç™¾åˆ†æ¯”
- **èµ„æºä½¿ç”¨**: CPU, å†…å­˜, GPUåˆ©ç”¨ç‡

### æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨

```bash
# å®æ—¶ç›‘æ§
docker stats embedding-service-gpu-prod

# æŸ¥çœ‹æ—¥å¿—
docker logs -f embedding-service-gpu-prod
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸è¦åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨Flaskå¼€å‘æœåŠ¡å™¨**
2. **GPUç‰ˆæœ¬å»ºè®®1-2ä¸ªworkers**ï¼ˆé¿å…æ˜¾å­˜ç«äº‰ï¼‰
3. **CPUç‰ˆæœ¬workersæ•° = CPUæ ¸å¿ƒæ•°**
4. **ç›‘æ§èµ„æºä½¿ç”¨ï¼ŒåŠæ—¶è°ƒæ•´é…ç½®**
5. **é«˜å¹¶å‘åœºæ™¯å»ºè®®å¤šå®ä¾‹éƒ¨ç½²**

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- [CONCURRENCY_ANALYSIS.md](CONCURRENCY_ANALYSIS.md) - è¯¦ç»†çš„æ€§èƒ½åˆ†æ
- [README.md](README.md) - å®Œæ•´çš„ä½¿ç”¨æ–‡æ¡£

